# Speech recognition




### Описание модуля

Модуль выполняет задачу распознавания аудио, с помощью комбинации методов описанных ниже:
1) Сплиттинг аудио по участкам тишины. (для того чтобы иметь возможность обрабатывать аудио большого размера; 
кроме того, это оказалось удобным для последующего слияния частей аудио на 3 этапе, потому что а основном
участки тишины соответствуют концам предложений в семантическом смысле).
2) Распознавание текста для каждого элемента сплиттинга ( = чанк = chunk) c помощью библиотеки NVIDIA Nemo. При этом 
пункт 3 становится необходимым, потому что распознавание местами происходит грамматически неправильно и, к тому же, Nemo не
добавляет пунктуацию в отличие от whisper. 
3) Корректировка грамматики, добавление пунктуации с помощью 
t5-russian-spell и дальнейшее слияние елементов в единый текст.  

Таким образом, модуль делает по сути тоже самое, что whisper, но точнее (в плане грамматики) и быстрее.



### Основные характеристики модуля:

- Поддержка input-а большого размера (например, аудио длинной 30 минут).
- Скорость работы примерно в 3 раза быстрее длины аудио (например, аудио длиной 30 минут обрабатывается 10 минут).
- Есть пунктуация.
- Большинство слов - грамматически корректны (надо будет это еще померить метрикой).

### Структура модуля

- **demo.py**: Демонстрационный файл, показывающий как использовать модуль.
- **SpeechRecognitionModule/**
  - **split_audio.py**: Файл содержит класс, который позволяет привести аудио к нужному формату (16К mono wav) и затем разбить его на части
  (длина каждой из которых ограничена) по участкам тишины, которые в основном семантически возникают на стыке предложений _(соответствует 1 этапу)_.
  - **raw_transcription.py**: Файл содержит в себе класс, для работы с этапом распознавания аудио в чанках с помощью NVIDIA Nemo _(соответствует 2 этапу)_.
  - **spelling_correction.py**: Файл содержит в себе класс для правки "сырого" текста, полученного путем первичной
  транскрибации c помощью Nemo, и расставления в нем пунктуации _(соответствует 3 этапу)_.
  - **transcribe.py**: Файл содержит функцию осуществляющую перевод аудио в текст _(соответствует объединению 1,2,3 этапов)_.
  - **utils.py**: Файл содержит в себе вспомогательные функции.
  - **exceptions.py**: Файл содержит в себе исключения.

### Пример использования модуля
```python
import torch
from SpeechRecognitionModule import speech2text

## Setting up parameters 
path2audio = "path/to/your/audio"
device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
verbose = 2  # 0 = just output, 1 = output + time stats, 2 = output + time stats + all in-between outputs


## Getting text from audio
output_text = speech2text(path2audio,
                          device,
                          verbose=2)
print(output_text)

```
